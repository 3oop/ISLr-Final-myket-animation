---
title: "ISL Final Project Phase III"
author: "Pooria Assarehha"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exploratory Data Analaysis

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrplot)
library(gridExtra)
library(tidyverse)
library(reshape2)
library(moments)
```

```{r}
file_path <- "C:/Users/SAM-Tech/Desktop/ISL/clean_data.csv"  
df <- read.csv(file_path, stringsAsFactors = TRUE)  
```

```{r}
summary_stats <- summary(df)
print(summary_stats)
```

Histograms for key numerical variables

```{r}
num_cols <- c("IMDB_Link", "Amtiaz", "Number_People", "Total_Episodes")

par(mfrow=c(2,2)) 
for (col in num_cols) {
  hist(df[[col]], main=paste("Distribution of", col), col="skyblue", border="black")
}
```

Correlation heatmap

```{r}
num_df <- df %>% select_if(is.numeric)
corr_matrix <- cor(num_df, use="complete.obs")

corrplot(corr_matrix, method="color", col=colorRampPalette(c("blue", "white", "red"))(200),
         tl.cex=0.35, tl.col="black", title="Correlation Heatmap")
```

Bar chart for Categorical Features, Country distribution

```{r}
ggplot(df, aes(x=Country)) +
  geom_bar(fill="skyblue", color="black") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  labs(title="Distribution of Movies by Country", x="Country", y="Count")
```

Bar chart for Rade distribution

```{r}
ggplot(df, aes(x=Rade)) +
  geom_bar(fill="orange", color="black") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  labs(title="Distribution of Movies by Rade", x="Rade", y="Count")
```

Outlier detection using boxplots

```{r}
numeric_features <- c("IMDB_Link", "Amtiaz", "Number_People", "Year", "Total_Episodes")
df_long <- df %>% select(all_of(numeric_features)) %>% pivot_longer(everything(), names_to="Feature", values_to="Value")
#df_melted <- melt(df, measure.vars = num_features)

ggplot(df_long, aes(x=Feature, y=Value)) +
  geom_boxplot(fill="lightblue", color="black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  labs(title="Boxplots of Key Numerical Features", x="Feature", y="Value")
```

Checking for Skewness and Distribution

```{r}
for (col in num_cols) {
  cat("Skewness of", col, ":", skewness(df[[col]], na.rm = TRUE), "\n")
}
```

Data Overview: The dataset contains 638 rows and 61 columns.
There are both numerical and categorical features.
Columns like URL, Name, and Rade are categorical, while others like IMDB_Link, Amtiaz, and Number_People are numerical.
The dataset has no missing values after preprocessing.

Numerical Features: IMDB_Link has values ranging from 2.1 to 9.3, with a mean of 6.84.
Amtiaz ranges from 17 to 100, with a mean of 84.6.
Number_People has high variance, ranging from 1,000 to 998,000.
Year values range from 1940 to 2025, with most data points concentrated in recent years.
Some numerical columns (like Total_Episodes) have skewed distributions, which might affect modeling.

Categorical Features: Country and Rade should be analyzed further with frequency counts.
Many binary genre columns (e.g., Romance, SciFi, Anime) are mostly 0s, meaning most movies don't belong to these genres.

Missing Values: No missing values are present after cleaning.

Correlation Analysis: Strong correlations exist between IMDB_Link, Amtiaz, and Number_People, indicating possible relationships worth exploring in modeling.

## Feature Selection

## Model Map

# simple linear regression

```{r}
set.seed(1)
n <- nrow(df)
train_idx <- sample(1:n, size = 0.7 * n)  
remaining_idx <- setdiff(1:n, train_idx)  
valid_idx <- sample(remaining_idx, size = 0.15 * n)  
test_idx <- setdiff(remaining_idx, valid_idx)  
train_data <- df[train_idx, ]
valid_data <- df[valid_idx, ]
test_data  <- df[test_idx, ]

linear_regression_model <- lm(Amtiaz~., data = train_data)
summary(linear_regression_model)$r.squared
```

# ridge regression

```{r}
library(glmnet)
x <- model.matrix(Amtiaz ~ ., df)[, -1]
y <- data$Amtiaz
x_train <- x[train_idx, ]
x_test <- x[-train_idx, ]
y_train <- y[train_idx]
y_test <- y[-train_idx]
ridge_cv <- cv.glmnet(x_train, y_train, alpha = 0, lambda = 10^seq(4, -2, length = 100))
best_lambda_ridge <- ridge_cv$lambda.min
cat("Optimal Lambda for Ridge: ", best_lambda_ridge, "\n")
#grid <- 10^seq(10, -2, length=100)
ridge_model <- glmnet(x_train, y_train, alpha = 0, lambda = best_lambda_ridge)
summary(ridge_model)
pred_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = x_test)
(mse <- mean((pred_ridge - y_test)^2))
```

# lasso regression

```{r}
lasso_cv <- cv.glmnet(x_train, y_train, alpha = 1, lambda = 10^seq(4, -2, length = 100))
best_lambda_lasso <- lasso_cv$lambda.min
cat("Optimal Lambda for Lasso: ", best_lambda_lasso, "\n")
#grid <- 10^seq(10, -2, length=100)
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda_lasso)
summary(lasso_model)
pred_lasso <- predict(lasso_model, s = best_lambda_lasso, newx = x_test)
(mse <- mean((pred_lasso - y_test)^2))
```


# GAM
```{r}
library(mgcv)
library(caret)
library(dplyr)
library(ggplot2)
```

```{r}
data = 'clean_data.csv'
df <- read.csv(data, stringsAsFactors = TRUE)
```

```{r}
df$Country <- factor(df$Country)
df$Rade <- factor(df$Rade)
df$Country <- factor(df$Country, levels = unique(df$Country))
df$Rade <- factor(df$Rade, levels = unique(df$Rade))
df$Year <- as.numeric(df$Year)
df$Amtiaz <- as.numeric(df$Amtiaz)
df$IMDB_Link <- as.numeric(df$IMDB_Link)
## Identify binary variables and convert them to factors
#binary_vars <- setdiff(names(df), c("Country", "Rade", "Year", "Amtiaz", "IMDB_Link"))
#df[binary_vars] <- lapply(df[binary_vars], as.factor)
```

```{r}
set.seed(123)
train_index <- sample(1:nrow(df), size = floor(0.8 * nrow(df)), replace = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

# Align test set factor levels with training set
test_data$Country <- factor(test_data$Country, levels = levels(train_data$Country))
test_data$Rade <- factor(test_data$Rade, levels = levels(train_data$Rade))
```

```{r}
gam_model <- gam(Amtiaz ~ s(Year) + s(IMDB_Link) + Country + Rade, data=train_data, method ="REML")

summary(gam_model)
```

```{r}
test_predictions <- predict(gam_model, newdata = test_data)

# Calculate test MSE and R-squared
mse_test <- mean((test_predictions - test_data$Amtiaz)^2)
rsq_test <- 1 - sum((test_predictions - test_data$Amtiaz)^2) / sum((mean(test_data$Amtiaz) - test_data$Amtiaz)^2)


train_predictions <- predict(gam_model, newdata = train_data)

# Calculate training MSE and R-squared
mse_train <- mean((train_predictions - train_data$Amtiaz)^2)
rsq_train <- 1 - sum((train_predictions - train_data$Amtiaz)^2) / sum((mean(train_data$Amtiaz) - train_data$Amtiaz)^2)

print(paste("Test Mean Squared Error:", mse_test))
print(paste("Test R-squared:", rsq_test))
print(paste("Train Mean Squared Error:", mse_train))
print(paste("Train R-squared:", rsq_train))
```

```{r}
plot(gam_model, pages = 1, shade = TRUE, col = "blue")

par(mfrow = c(2, 2))
gam.check(gam_model)
```

```{r}
ata.frame(Actual = test_data$Amtiaz, Predicted = test_predictions), 
       aes(x = Actual, y = Predicted)) +
  geom_point(color = "blue") +
  geom_abline(intercept = 0, slope = 1, col = "red", linetype = "dashed") +
  labs(title = "GAM Predictions vs. Actual Values",
       x = "Actual Amtiaz",
       y = "Predicted Amtiaz") +
  theme_minimal()
```





# random forest

```{r}
library(randomForest)
library(tidyverse)
library(caret)
```

```{r}
data = 'clean_data.csv'
df <- read.csv(data, stringsAsFactors = TRUE)
```

```{r}
# Convert columns 
df$Country <- as.factor(df$Country)
df$Rade <- as.factor(df$Rade)
df$Year <- as.numeric(df$Year)
df$Amtiaz <- as.numeric(df$Amtiaz)
df$IMDB_Link <- as.numeric(df$IMDB_Link)
# Convert all other binary variables to factor
#binary_vars <- setdiff(names(df), c("Country", "Rade", "Year", "Amtiaz", "IMDB_Link"))
#df[binary_vars] <- lapply(df[binary_vars], as.factor)
```

```{r}
set.seed(123)
train_index <- sample(1:nrow(df), size = floor(0.8 * nrow(df)), replace = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
```

```{r}
target <- "Amtiaz"
predictors <- setdiff(names(df), target)
```

```{r}
rf_model <- randomForest(Amtiaz ~ ., data = train_data, ntree = 100, mtry = 3, importance = TRUE)
print(rf_model)
```

```{r}
predictions <- predict(rf_model, test_data)
head(predictions)

# For regression tasks, Mean Squared Error (MSE)
mse <- mean((predictions - test_data$Amtiaz)^2)
print(paste("Mean Squared Error:", mse))
```

```{r}
tuned_rf <- tuneRF(train_data[-which(names(train_data) == "Amtiaz")], train_data$Amtiaz, stepFactor = 1.5, improve = 0.01, ntreeTry = 100)
print(tuned_rf)
```

```{r}
importance(rf_model)
varImpPlot(rf_model)
```

```{r}
rsq <- 1 - sum((predictions - test_data$Amtiaz)^2) / sum((mean(test_data$Amtiaz) - test_data$Amtiaz)^2)
print(paste("R-squared:", rsq))
```

# SVR

```{r}
library(e1071)
library(caret)
library(dplyr)
```

```{r}
data = 'clean_data.csv'
df <- read.csv(data, stringsAsFactors = TRUE)
```

```{r}
# Convert columns 
df$Country <- as.factor(df$Country)
df$Rade <- as.factor(df$Rade)
df$Amtiaz <- as.numeric(df$Amtiaz)
df$Year <- as.numeric(df$Year)
df$IMDB_Link <- as.numeric(df$IMDB_Link)
# Convert categorical variables to dummy variables
df <- dummyVars(~ ., data = df) %>% predict(df) %>% as.data.frame()
```

Split the data into features and target

```{r}
target <- "Amtiaz"
predictors <- setdiff(names(df), target)

# or
#features <- data[,-which(names(data) == "Amtiaz")]
#target <- data$Amtiaz
```

train,test

```{r}
set.seed(123)
train_index <- sample(1:nrow(df), size = floor(0.8 * nrow(df)), replace = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

# Scale numerical features
preproc <- preProcess(train_data[, predictors], method = c("center", "scale"))
train_data_scaled <- predict(preproc, train_data)
test_data_scaled <- predict(preproc, test_data)

train_data_scaled$Amtiaz <- train_data$Amtiaz
test_data_scaled$Amtiaz <- test_data$Amtiaz
```

```{r}
svr_model <- svm(Amtiaz ~ ., data = train_data_scaled, kernel = "radial", cost = 1, gamma = 0.1)

plot(svr_model, train_data_scaled)
summary(svr_model)
```

```{r}
predictions <- predict(svr_model,test_data_scaled)
head(predictions)

mse <- mean((predictions - test_data_scaled$Amtiaz)^2)
print(paste("Mean Squared Error:", mse))

r2 <- cor(predictions, test_data_scaled$Amtiaz)^2
print(paste("R-squared:", r2))

# Plot actual vs predicted values
plot(test_data_scaled$Amtiaz, predictions, 
     xlab = "Actual Amtiaz", ylab = "Predicted Amtiaz",
     main = "SVR Predictions vs. Actual Values",
     col = "green", pch = 16)
abline(0, 1, col = "red", lwd = 2)
```

```{r}
tuned <- tune(svm, Amtiaz ~ ., data = train_data_scaled,kernel = "radial", ranges = list(cost =c(0.1, 1, 10), gamma = c(0.01, 0.1, 1)))
best_model <- tuned$best.model
summary(best_model)
```

# RNN
```{r}
library(keras3)
RNN_model = keras_model_sequential() %>%
  layer_simple_rnn(units = 10, activation = "relu", input_shape = c(1350, 1)) %>%
  layer_dense(units = 1)

RNN_model %>% compile(
  optimizer = "adam",
  loss = "mse"
)

summary(RNN_model)

history = RNN_model %>% fit(
  x_train, y_train,
  epochs = 10, batch_size = 16,
  validation_data = list(x_test, y_test),
  verbose = 1
)

y_pred = RNN_model %>% predict(x_test)
(mse = mean((y_pred- y_test)^2))
```





1)	Simple Linear Regression
This model is often the first approach to try when you believe the relationship between the variables is linear.
Pros:
Easy to implement and interpret.
Provides a clear and direct relationship between the predictor and the outcome.
Cons:
Assumes a linear relationship; might not work well if the relationship is nonlinear.
Sensitive to outliers.
the relationship between the predictors and the target is nonlinear, a more complex model is needed, like multiple regression.


2)	Ridge Regression
we have correlation among the predictors. It adds a penalty term to the least squares estimation, shrinking the coefficients to prevent overfitting. While simple linear regression is easy to implement, it doesn’t handle multicollinearity well, and its performance can degrade when predictors are highly correlated.
Pros:
Reduces model complexity and prevents overfitting by regularizing the coefficients.
Useful in high-dimensional datasets.
Cons:
Does not perform feature selection (all features are included in the model).
The results might be harder to interpret due to the regularization.
We want to perform feature selection, lasso regression might be a better choice.


3)	Lasso Regression
Ridge regression shrinks coefficients but does not perform feature selection, meaning all features remain in the model, which can make interpretation difficult. Lasso regression, on the other hand, performs both regularization and feature selection by driving some coefficients to zero. This leads to a simpler, more interpretable model with fewer predictors. This is useful when we have some irrelevant predictors.
Pros:
Performs feature selection, resulting in simpler, more interpretable models.
Effective when there are many irrelevant or redundant features.
Cons:
Might eliminate useful predictors if the penalty is too high.
We use lasso regression to perform feature selection in addition to regularization.


4)	Generalized Additive Model (GAM)
This model allows for nonlinear relationships between predictors and the target variable(Amtiaz) and it fits a separate smoother for each predictor. The relationship between the predictors and Amtiaz is nonlinear but we want interpretability. While lasso regression is useful for regularization and feature selection, it assumes a linear relationship between the predictors and the target. GAM offers greater flexibility when the relationship is nonlinear and allows each predictor to have a nonlinear effect, improving model performance when there is no simple linear relationship.
Pros:
Allows for nonlinear relationships, providing flexibility in modeling complex data.
More interpretable than non-parametric models like random forests.
Cons:
Can be computationally expensive.
Requires careful tuning of smoothers.


5)	Random Forest
It is particularly useful for capturing complex, nonlinear relationships in the data. GAM is interpretable but might not perform as well as some machine learning methods when it comes to complex, high-dimensional data. We have a large number of predictors and complex interactions so that is why we use this model.
Pros:
Handles both numerical and categorical data.
Robust to overfitting and performs well even with noisy data.
Cons:
Less interpretable compared to simpler models.
Computationally expensive and can become slow with large datasets.


6)	Support Vector Regression (SVR)
t tries to find a hyperplane that best separates the data with a margin, handling nonlinear relationships using kernel functions. We have a dataset and need a powerful, nonlinear model that can handle complex relationships. Also the R-square of tree is low.
Pros:
Works well for high-dimensional spaces.
Robust to overfitting, especially in high-dimensional space.
Cons:
Sensitive to the choice of the kernel and hyperparameters.
Computationally expensive for large datasets.


7)	Neural Networks (NN)
This model is highly flexible and capable of learning complex patterns in the data through layers of interconnected nodes.
Pros:
Extremely powerful and flexible for modeling complex, nonlinear relationships.
Can learn intricate patterns from large datasets.
Cons:
Difficult to interpret due to the "black-box" nature.






