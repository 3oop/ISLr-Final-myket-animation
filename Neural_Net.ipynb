{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01c87f6-dfce-4b73-80d3-5954ee5ddac7",
   "metadata": {},
   "source": [
    "# fit a Neural Network to Myket Animation data\n",
    "\n",
    "Our Data consists mainly of 2lvl binary factors, and our task is regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bafb66e-1e44-48ff-b9a5-7216c6beea88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import set_random_seed, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a6597-c3b5-4cf6-bca3-b031510b6013",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d655215-7a2f-47b8-8c9f-c0d38bfea81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'clean_data.csv'\n",
    "\n",
    "def load_data(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        assert df.isna().sum().sum() == 0 # first sum() to sum on each column, second to sum() on all columns\n",
    "    except FileNotFoundError:\n",
    "        msg = \"Expected data file not found, you must run Data Collection and Data Cleaning procedures. follow instructions in README.txt\"\n",
    "        raise FileNotFoundError(msg)\n",
    "    except AssertionError:\n",
    "        msg = 'Data has missing values, Run Cleaning notebooks first maybe there is a problem there.'\n",
    "        raise AssertionError(msg)\n",
    "    return df\n",
    "\n",
    "df = load_data(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be072c9-83e7-46ef-8efa-883c9b7b22df",
   "metadata": {},
   "source": [
    "### Data Preperation And Train/Test Split \n",
    "\n",
    "\n",
    "Important considerations:\n",
    "- Tensorflow/keras only accepts numerical features. onehot encoding can be performed categories.\n",
    "- `URL` and `Name` must not be given to the model.\n",
    "- `Year` is categorical or numerical?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73ad5197-95de-44f5-9271-3d3143f94084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(file)\n",
    "\n",
    "# Identify categorical columns (excluding URL & Name)\n",
    "categorical_cols = [col for col in df.columns if (col not in ['URL', 'Name']) and (df[col].dtype == 'object')]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_categories = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Convert to DataFrame\n",
    "enc_df = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out(categorical_cols), index=df.index)\n",
    "\n",
    "# Drop original categorical columns and merge encoded features\n",
    "df = df.drop(columns=categorical_cols).join(enc_df)\n",
    "\n",
    "# Convert numeric categorical features (2-level factors) to integer\n",
    "binary_cols = ['Num_Seasons', 'Total_Episodes', 'Publication', 'VoiceActors', 'Review', 'Tips', 'End', 'Description', \n",
    "               'Characters', 'InformativeMessages', 'PositiveAndNegative', 'SummaryStory', 'Screening', 'Critics', \n",
    "               'Conclusion', 'Introduction', 'Is_Doblele', 'Series', 'Animation', 'Western', 'Adventure', 'Comedy', \n",
    "               'Family', 'Fantasy', 'Mystery', 'Action', 'Romance', 'Drama', 'SciFi', 'ShortFilm', 'Crime', \n",
    "               'Musical', 'Korean', 'Thriller', 'Anime', 'Music']\n",
    "\n",
    "df[binary_cols] = df[binary_cols].astype(np.int64)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'URL', 'Name'])\n",
    "\n",
    "# Scale continuous features\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "continuous_x_cols = ['IMDB_Link', 'Number_People', 'Total_Words', 'Num_Titles', 'Total_Target_Words', \n",
    "                   'About_Words', 'Story_Words', 'Release_Date_Words', 'Review_Words', 'Final_Words', \n",
    "                   'Informative_Words', 'Positive_Negative_Words', 'Summary_Words', 'Screening_Words', \n",
    "                   'Critics_Words', 'Conclusion_Words', 'Introduction_Words', 'Voice_Actor_Words']\n",
    "\n",
    "\n",
    "df[continuous_x_cols] = x_scaler.fit_transform(df[continuous_x_cols])\n",
    "df['Amtiaz'] = y_scaler.fit_transform(df['Amtiaz'].to_numpy().reshape((-1,1)))\n",
    "\n",
    "# Set random seed\n",
    "set_random_seed(14)\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=14)\n",
    "\n",
    "# Define target and feature sets\n",
    "y_train = train_df.pop('Amtiaz')\n",
    "y_test = test_df.pop('Amtiaz')\n",
    "x_train = train_df\n",
    "x_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb481f95-7e4b-4260-9986-ba4e387aac5b",
   "metadata": {},
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6545b9f2-55af-45eb-b356-b1060b356568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │           \u001b[38;5;34m5,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m1,830\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m155\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,391</span> (28.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,391\u001b[0m (28.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,391</span> (28.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,391\u001b[0m (28.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "L1 = 60  # nodes in layer 1\n",
    "L2 = 30  # nodes in layer 2\n",
    "L3 = 5  # nodes in layer 2\n",
    "learning_rate = 0.001  # upper limit for Adam optimizer\n",
    "lmbda = 0.0001\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape =(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(units=L1, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=L2, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=L3, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)  # Regression task\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "model.compile(optimizer=optimizer, loss=mse, metrics=['mae'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c0051aab-d976-461c-98c7-a1388d37cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0153 - mae: 0.7804 - val_loss: 2.5198 - val_mae: 1.4948\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0303 - mae: 0.7883 - val_loss: 2.6686 - val_mae: 1.5433\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0426 - mae: 0.7959 - val_loss: 2.7695 - val_mae: 1.5746\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0536 - mae: 0.8015 - val_loss: 2.7837 - val_mae: 1.5779\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0589 - mae: 0.8035 - val_loss: 2.7052 - val_mae: 1.5519\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0592 - mae: 0.8012 - val_loss: 2.6014 - val_mae: 1.5170\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0627 - mae: 0.8019 - val_loss: 2.4686 - val_mae: 1.4711\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0670 - mae: 0.8062 - val_loss: 2.3357 - val_mae: 1.4239\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0748 - mae: 0.8117 - val_loss: 2.2147 - val_mae: 1.3791\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0827 - mae: 0.8171 - val_loss: 2.1106 - val_mae: 1.3382\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0949 - mae: 0.8255 - val_loss: 2.0950 - val_mae: 1.3313\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0984 - mae: 0.8280 - val_loss: 2.0740 - val_mae: 1.3201\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1364 - mae: 0.8468 - val_loss: 2.2122 - val_mae: 1.3698\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1729 - mae: 0.8642 - val_loss: 2.3008 - val_mae: 1.4019\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2329 - mae: 0.8914 - val_loss: 2.4731 - val_mae: 1.4585\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2678 - mae: 0.9083 - val_loss: 2.6113 - val_mae: 1.5051\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3231 - mae: 0.9326 - val_loss: 2.7420 - val_mae: 1.5426\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3498 - mae: 0.9452 - val_loss: 2.8680 - val_mae: 1.5800\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3772 - mae: 0.9568 - val_loss: 2.9337 - val_mae: 1.5991\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3882 - mae: 0.9616 - val_loss: 2.9819 - val_mae: 1.6127\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3828 - mae: 0.9612 - val_loss: 3.0502 - val_mae: 1.6332\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3907 - mae: 0.9651 - val_loss: 3.1084 - val_mae: 1.6492\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3982 - mae: 0.9690 - val_loss: 3.1168 - val_mae: 1.6522\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3932 - mae: 0.9681 - val_loss: 3.1616 - val_mae: 1.6629\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3841 - mae: 0.9640 - val_loss: 3.1162 - val_mae: 1.6530\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3839 - mae: 0.9675 - val_loss: 3.1528 - val_mae: 1.6578\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3559 - mae: 0.9541 - val_loss: 3.1225 - val_mae: 1.6525\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3420 - mae: 0.9502 - val_loss: 3.1022 - val_mae: 1.6465\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3278 - mae: 0.9453 - val_loss: 3.0195 - val_mae: 1.6242\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3066 - mae: 0.9379 - val_loss: 2.9667 - val_mae: 1.6073\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2752 - mae: 0.9245 - val_loss: 2.8667 - val_mae: 1.5788\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2423 - mae: 0.9108 - val_loss: 2.7939 - val_mae: 1.5549\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2168 - mae: 0.8993 - val_loss: 2.6778 - val_mae: 1.5207\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1763 - mae: 0.8800 - val_loss: 2.5443 - val_mae: 1.4788\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1301 - mae: 0.8561 - val_loss: 2.4193 - val_mae: 1.4410\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0910 - mae: 0.8373 - val_loss: 2.2840 - val_mae: 1.3928\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0373 - mae: 0.8088 - val_loss: 2.1236 - val_mae: 1.3380\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0004 - mae: 0.7861 - val_loss: 1.9609 - val_mae: 1.2786\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9597 - mae: 0.7628 - val_loss: 1.8092 - val_mae: 1.2151\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9210 - mae: 0.7423 - val_loss: 1.6398 - val_mae: 1.1432\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8845 - mae: 0.7237 - val_loss: 1.4784 - val_mae: 1.0686\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8525 - mae: 0.7063 - val_loss: 1.3515 - val_mae: 1.0062\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8299 - mae: 0.6936 - val_loss: 1.2591 - val_mae: 0.9576\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8162 - mae: 0.6857 - val_loss: 1.1453 - val_mae: 0.8933\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8018 - mae: 0.6770 - val_loss: 1.0174 - val_mae: 0.8145\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7856 - mae: 0.6680 - val_loss: 0.9261 - val_mae: 0.7524\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7813 - mae: 0.6653 - val_loss: 0.8595 - val_mae: 0.6986\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7665 - mae: 0.6583 - val_loss: 0.8425 - val_mae: 0.6850\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7659 - mae: 0.6581 - val_loss: 0.8090 - val_mae: 0.6554\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7557 - mae: 0.6510 - val_loss: 0.8079 - val_mae: 0.6524\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7006 - mae: 0.5965\n",
      "Test Loss: 0.8079, Test MAE: 0.6524\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=50,  # You can increase epochs for better performance\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2b7d4-77cd-4406-96ce-b2799bbd97e8",
   "metadata": {},
   "source": [
    "This at last is the minimum MSE obtained. I changed `L1`, `L2`, `L3`, `learning_rate` by hand, no grid search for tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dfa12932-ddb7-444b-8a65-71775b7d01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "R²: 0.0409\n",
      "Adjusted R²: -2.2054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def adjusted_r2(y_true, y_pred, n, p):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "# Example usage:\n",
    "y_pred = model.predict(x_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adj_r2 = adjusted_r2(y_test, y_pred, n=x_test.shape[0], p=x_test.shape[1])\n",
    "\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"Adjusted R²: {adj_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd1162-621a-4f2c-bc4d-4cdae00e06bc",
   "metadata": {},
   "source": [
    "Surely you are joking Mr.Feynman! This means what our model is predicting is no better than predicting the mean value! let's examine `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "408d5de6-ebf5-4d4f-93a2-be60d1a87015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [96.], Predicted: [83.22892]\n",
      "Actual: [90.], Predicted: [91.00413]\n",
      "Actual: [84.], Predicted: [77.41638]\n",
      "Actual: [75.], Predicted: [80.172226]\n",
      "Actual: [94.], Predicted: [78.40123]\n",
      "Actual: [85.], Predicted: [87.41065]\n",
      "Actual: [86.], Predicted: [83.06726]\n",
      "Actual: [78.], Predicted: [79.49491]\n",
      "Actual: [89.], Predicted: [86.618195]\n",
      "Actual: [88.], Predicted: [87.37692]\n",
      "Actual: [92.], Predicted: [75.05681]\n",
      "Actual: [96.], Predicted: [91.544205]\n",
      "Actual: [70.], Predicted: [74.79234]\n",
      "Actual: [83.], Predicted: [80.23523]\n",
      "Actual: [86.], Predicted: [76.48962]\n",
      "Actual: [84.], Predicted: [84.60321]\n",
      "Actual: [82.], Predicted: [76.87033]\n",
      "Actual: [87.], Predicted: [80.84146]\n",
      "Actual: [75.], Predicted: [81.8219]\n",
      "Actual: [88.], Predicted: [82.12972]\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred.reshape(-1, 1)  # Reshape to (n_samples, 1)\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "yhat = y_scaler.inverse_transform(y_pred)\n",
    "y = y_scaler.inverse_transform(y_test.to_numpy().reshape(-1, 1))  # Reshape y_test to (n_samples, 1)\n",
    "\n",
    "# Print first 10 predictions vs actual values\n",
    "for i, j in zip(y[:20], yhat[:20]):\n",
    "    print(f\"Actual: {i}, Predicted: {j}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137f376-bf82-4671-87e0-5a33d03527c1",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "we would like to proceed but `GridSearchCV` from `sklearn` has some compatibility issues with recent versions of t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a00e4447-01ff-4df7-9340-a9133e1d3408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers.scikit_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers.scikit_learn'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Define the model\n",
    "def create_model(l1=0.01, l2=0.01, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(128, activation='relu', \n",
    "                              kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Wrap the model for use with GridSearchCV\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Define grid search parameters\n",
    "param_grid = {\n",
    "    'l1': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'l2': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# GridSearchCV to tune hyperparameters\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and performance\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_result.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04e29b-ef49-4930-9244-680edfd32ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
